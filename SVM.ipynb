{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 6809272,
          "sourceType": "datasetVersion",
          "datasetId": 3917177
        }
      ],
      "dockerImageVersionId": 30558,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'cats-and-dogs:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F3917177%2F6809272%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240317%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240317T063654Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4d00bf379720e748d0e12d5f63c71a8772a0f3b193bb62d66fd8f672149aea10d1d9cbe567d4f5afda131325176b60c7196e403e16e4920fa55eea44a90cc5adbaab69f98600e965a4e60ba5e83a8e940dbc422fddf5c340229a6ec78e959f7c34aece975562054fcd987c1839c3a0763f2510832aa1354f880787effabf2fc1f041a563e9d5877d0e13b6085c633591d2561f9b481edb82de1b0feac3dae2bbc1471238ff0baaa7dfb3ff50d30dfc90048b86cdaaeabf0a823a0ecd510f0ef238e7823c8a26d29919f11ed302cfd53074a8ab281ed556ef681cef6941468b84b411d02094dcea744a21f58395c3165d54748ddfcdcf5d9418b8602016dd4156'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "GRNufBfoILSB"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "uamkLe5wILSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
        "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
        "import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n",
        "import torchvision\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torchvision import models\n",
        "from torch.utils.data import ( Dataset, DataLoader,random_split)\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-16T14:03:25.32469Z",
          "iopub.execute_input": "2023-11-16T14:03:25.325313Z",
          "iopub.status.idle": "2023-11-16T14:03:31.63454Z",
          "shell.execute_reply.started": "2023-11-16T14:03:25.325272Z",
          "shell.execute_reply": "2023-11-16T14:03:31.633415Z"
        },
        "trusted": true,
        "id": "bc08TzBOILSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.googlenet(weights=\"DEFAULT\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-16T14:03:38.802142Z",
          "iopub.execute_input": "2023-11-16T14:03:38.802719Z",
          "iopub.status.idle": "2023-11-16T14:03:39.575624Z",
          "shell.execute_reply.started": "2023-11-16T14:03:38.802685Z",
          "shell.execute_reply": "2023-11-16T14:03:39.574104Z"
        },
        "trusted": true,
        "id": "4wFcUKK3ILSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CatsAndDogsDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.annotations = pd.read_csv('/kaggle/input/cats-and-dogs/train.csv')\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
        "        image = Image.open(img_path)\n",
        "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return (image, y_label)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-16T14:03:42.026332Z",
          "iopub.execute_input": "2023-11-16T14:03:42.026745Z",
          "iopub.status.idle": "2023-11-16T14:03:42.036507Z",
          "shell.execute_reply.started": "2023-11-16T14:03:42.026712Z",
          "shell.execute_reply": "2023-11-16T14:03:42.03527Z"
        },
        "trusted": true,
        "id": "G6McIJFoILSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_channel = transforms.Resize(256)\n",
        "num_classes = 2\n",
        "learning_rate = 0.00001\n",
        "num_epochs = 10\n",
        "batch_size = 64\n",
        "target_size = (32,32)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-16T14:05:43.74489Z",
          "iopub.execute_input": "2023-11-16T14:05:43.745334Z",
          "iopub.status.idle": "2023-11-16T14:05:43.751346Z",
          "shell.execute_reply.started": "2023-11-16T14:05:43.745299Z",
          "shell.execute_reply": "2023-11-16T14:05:43.7502Z"
        },
        "trusted": true,
        "id": "Z3kEA2FUILSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CatsAndDogsDataset(\n",
        "    csv_file ='/kaggle/input/cats-and-dogs/train.csv',\n",
        "    root_dir = '/kaggle/input/cats-and-dogs',\n",
        "    transform = transforms.Compose([transforms.Resize((32,32)),\n",
        "                                    transforms.ToTensor(),\n",
        "                                   ])\n",
        ")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-16T14:03:46.982006Z",
          "iopub.execute_input": "2023-11-16T14:03:46.982638Z",
          "iopub.status.idle": "2023-11-16T14:03:47.007105Z",
          "shell.execute_reply.started": "2023-11-16T14:03:46.982603Z",
          "shell.execute_reply": "2023-11-16T14:03:47.005996Z"
        },
        "trusted": true,
        "id": "7-WyZxt6ILSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.7 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_set, test_set = random_split(dataset, [train_size, test_size])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-16T14:03:48.348061Z",
          "iopub.execute_input": "2023-11-16T14:03:48.34847Z",
          "iopub.status.idle": "2023-11-16T14:03:48.361077Z",
          "shell.execute_reply.started": "2023-11-16T14:03:48.348438Z",
          "shell.execute_reply": "2023-11-16T14:03:48.360046Z"
        },
        "trusted": true,
        "id": "eY5ggsTGILSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_set, batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_set, batch_size, shuffle=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-16T14:04:34.468383Z",
          "iopub.execute_input": "2023-11-16T14:04:34.468771Z",
          "iopub.status.idle": "2023-11-16T14:04:34.475563Z",
          "shell.execute_reply.started": "2023-11-16T14:04:34.468742Z",
          "shell.execute_reply": "2023-11-16T14:04:34.473587Z"
        },
        "trusted": true,
        "id": "MQp-2EXPILSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-15T11:39:50.933972Z",
          "iopub.execute_input": "2023-11-15T11:39:50.935009Z",
          "iopub.status.idle": "2023-11-15T11:39:50.940659Z",
          "shell.execute_reply.started": "2023-11-15T11:39:50.93496Z",
          "shell.execute_reply": "2023-11-15T11:39:50.939859Z"
        },
        "trusted": true,
        "id": "Yo5GurbLILSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc = nn.Linear(in_features=1024, out_features=num_classes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-16T14:03:56.266712Z",
          "iopub.execute_input": "2023-11-16T14:03:56.267094Z",
          "iopub.status.idle": "2023-11-16T14:03:56.274102Z",
          "shell.execute_reply.started": "2023-11-16T14:03:56.267064Z",
          "shell.execute_reply": "2023-11-16T14:03:56.272827Z"
        },
        "trusted": true,
        "id": "ZHxd5FXUILSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "# Train Network\n",
        "for epoch in range(num_epochs):\n",
        "    losses = []\n",
        "    for batch_idx, (data, targets) in enumerate(train_dataloader):\n",
        "        # Get data to cuda if possible\n",
        "        data = data\n",
        "        targets = targets\n",
        "        # forward\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "        losses.append(loss.item())\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # gradient descent or adam step\n",
        "        optimizer.step()\n",
        "    print(f\"Cost at epoch {epoch} is {sum(losses)/len(losses)}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-16T14:05:49.844428Z",
          "iopub.execute_input": "2023-11-16T14:05:49.844815Z",
          "iopub.status.idle": "2023-11-16T14:06:05.821132Z",
          "shell.execute_reply.started": "2023-11-16T14:05:49.844786Z",
          "shell.execute_reply": "2023-11-16T14:06:05.820018Z"
        },
        "trusted": true,
        "id": "YQHXUo_VILSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x\n",
        "            y = y\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "        print(\n",
        "            f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\n",
        "        )\n",
        "    model.train()\n",
        "print(\"Checking accuracy on Training Set\")\n",
        "check_accuracy(train_dataloader, model)\n",
        "print(\"Checking accuracy on Test Set\")\n",
        "check_accuracy(test_dataloader, model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-16T14:06:08.606195Z",
          "iopub.execute_input": "2023-11-16T14:06:08.60676Z",
          "iopub.status.idle": "2023-11-16T14:06:09.962299Z",
          "shell.execute_reply.started": "2023-11-16T14:06:08.606714Z",
          "shell.execute_reply": "2023-11-16T14:06:09.960018Z"
        },
        "trusted": true,
        "id": "a1Bqq0IcILSa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}